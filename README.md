# Machine Learning Notebook Collection

This repository contains a comprehensive set of Jupyter notebooks covering essential Machine Learning concepts, preprocessing techniques, and model building with practical examples.

## Contents

| Notebook | Description |
|----------|-------------|
| `Data_Preprocessing.ipynb` | Covers handling missing values, encoding, scaling, and feature selection. |
| `Feature_Engineering_CategoricalData.ipynb` | Techniques for encoding and transforming categorical variables. |
| `Feature_Engineering_NumericalData.ipynb` | Feature transformations like binning, scaling, and polynomial features for numerical data. |
| `SimpleLinearRegression.ipynb` | Linear regression using one independent variable. |
| `MultipleLinearRegression.ipynb` | Extends linear regression to multiple variables. |
| `PolynomialRegression.ipynb` | Adds polynomial terms to capture non-linear trends. |
| `Logistic_Regression.ipynb` | Classification model for binary outcomes using logistic regression. |
| `binaryClassification.ipynb` | Example of binary classification using ML models. |
| `DecisionTree.ipynb` | Implementation of decision trees for classification/regression. |
| `RandomForest.ipynb` | Ensemble method using multiple decision trees. |
| `Ensemble_learning.ipynb` | Overview of Bagging, Boosting, and Stacking techniques. |
| `SRV.ipynb` | Support Vector Regression to handle non-linear regression problems. |
| `KMeansClustering.ipynb` | Unsupervised learning using the K-Means algorithm. |
| `K_Fold & Grid Search.ipynb` | Model evaluation with cross-validation and hyperparameter tuning. |

