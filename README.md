# Machine Learning Notebook Collection

This repository contains a comprehensive set of Jupyter notebooks covering essential Machine Learning concepts, preprocessing techniques, and model building with practical examples.

## Contents

| Notebook | Description |
|----------|-------------|
| `Data_Preprocessing` | Covers handling missing values, encoding, scaling, and feature selection. |
| `Feature_Engineering_CategoricalData` | Techniques for encoding and transforming categorical variables. |
| `Feature_Engineering_NumericalData` | Feature transformations like binning, scaling, and polynomial features for numerical data. |
| `SimpleLinearRegression` | Linear regression using one independent variable. |
| `MultipleLinearRegression` | Extends linear regression to multiple variables. |
| `PolynomialRegression` | Adds polynomial terms to capture non-linear trends. |
| `Logistic_Regression` | Classification model for binary outcomes using logistic regression. |
| `binaryClassification` | Example of binary classification using ML models. |
| `DecisionTree` | Implementation of decision trees for classification/regression. |
| `RandomForest` | Ensemble method using multiple decision trees. |
| `Ensemble_learning` | Overview of Bagging, Boosting, and Stacking techniques. |
| `SRV` | Support Vector Regression to handle non-linear regression problems. |
| `KMeansClustering` | Unsupervised learning using the K-Means algorithm. |
| `K_Fold & Grid Search` | Model evaluation with cross-validation and hyperparameter tuning. |

